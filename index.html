<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8" />
  <title>ã¦ã‚“ãã™ã‚“ã€‚</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.16.0/dist/tf.min.js"></script>
  <!-- piexifjs: JPEGã«EXIFã‚’åŸ‹ã‚è¾¼ã‚€ãŸã‚ -->
  <script src="https://cdn.jsdelivr.net/npm/piexifjs@1.0.6/piexif.min.js"></script>

  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <style>
    body { font-family: sans-serif; background: #f2f2f2; padding: 2em; }
    .container { background: #fff; max-width: 420px; margin: auto; border-radius: 10px; box-shadow: 0 0 10px #ccc; padding: 2em; }
    h1 { color: #c46b9e; text-align: center; }
    label { display: block; margin-top: 1em; }
    input[type="file"] { width: 100%; }
    .controls { display: flex; gap: 0.5em; margin-top: 0.8em; }
    .controls button { flex: 1; padding: 0.6em; background: #c46b9e; color: #fff; border: none; border-radius: 5px; font-size: 0.95em; cursor: pointer; }
    button[type="submit"] { margin-top: 1.2em; width: 100%; padding: 0.8em; background: #c46b9e; color: #fff; border: none; border-radius: 5px; font-size: 1.1em; cursor: pointer; }
    .result { margin-top: 2em; font-size: 1.2em; text-align: center; }
    .healthy { color: #2bbd7e; }
    .sick { color: #e84c3d; }
    .preview { margin-top: 1em; max-width: 100%; border-radius: 8px; display:block; }
    .model-status { font-size: 0.95em; color: #888; margin-top: 0.5em; text-align: center; }

    /* video wrapper: fixed frame; internal video can be transformed without changing frame */
    .video-wrapper {
      width: 100%;
      aspect-ratio: 1 / 1;
      position: relative;
      overflow: hidden;
      border-radius: 8px;
      background: #000;
      margin-top: 1em;
    }
    video.main {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%) scale(1);
      transform-origin: center center;
      min-width: 100%;
      min-height: 100%;
      width: auto;
      height: auto;
      display: none;
      will-change: transform;
    }

    /* overlay preview shown inside videoWrapper when toggled */
    .overlay-preview {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
      display: none;
      z-index: 5;
      border-radius: 8px;
      background: #000;
      cursor: pointer;
    }

    /* preview thumbnail area */
    .preview-thumb {
      margin-top: 0.6em;
      display: flex;
      gap: 0.6em;
      align-items: center;
      justify-content: flex-start;
    }
    .preview-thumb img {
      width: 80px;
      height: 80px;
      object-fit: cover;
      border-radius: 6px;
      border: 1px solid #ddd;
      cursor: pointer;
      display: block;
    }
    /* mini simple camera shown in thumbnail area (no controls/zoom) */
    .mini-camera {
      width: 80px;
      height: 80px;
      border-radius: 6px;
      overflow: hidden;
      background: #000;
      border: 1px solid #ddd;
      display: none;
      cursor: pointer;
    }
    .mini-camera video {
      width: 100%;
      height: 100%;
      object-fit: cover;
    }

    .preview-thumb .txt { color:#666; font-size:0.9em; }

    .zoom-control { margin-top: 0.6em; display: none; align-items: center; gap: 0.6em; }
    .zoom-control input[type="range"] { width: 100%; }
    .zoom-value { min-width: 48px; text-align: right; font-size: 0.95em; color: #444; }

    /* brightness control: placed under zoom-control */
    .brightness-control { margin-top: 0.4em; display: none; align-items: center; gap: 0.6em; }
    .brightness-control input[type="range"] { width: 100%; }
    .brightness-value { min-width: 56px; text-align: right; font-size: 0.95em; color: #444; }

    /* download button style */
    #downloadBtn {
      margin-left: auto;
      padding: 0.45em 0.6em;
      background: #4a90e2;
      color: #fff;
      border: none;
      border-radius: 6px;
      cursor: pointer;
      font-size: 0.9em;
    }
    #downloadBtn[disabled] { opacity: 0.5; cursor: default; background: #9fbce9; }

    .small-note { font-size: 0.85em; color: #666; margin-top:0.5em; text-align:center; }
    .muted { color:#888; font-size:0.9em; margin-top:0.5em; text-align:center; }
  </style>
</head>
<body>
  <div class="container">
    <h1>ğŸŒ¸ã¦ã‚“ãã™ã‚“ã€‚ğŸŒ¸</h1>
    <div id="modelStatus" class="model-status"></div>

    <form id="sakuraForm">
      <label>ã‚µã‚¯ãƒ©ã®å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ã‚«ãƒ¡ãƒ©ã§æ’®å½±ã—ã¦ãã ã•ã„</label>

      <input type="file" id="imageInput" accept="image/*" />

      <div class="controls">
        <button type="button" id="toggleCamera">ã‚«ãƒ¡ãƒ©èµ·å‹•</button>
        <button type="button" id="switchCamera" disabled>ã‚«ãƒ¡ãƒ©åˆ‡æ›¿</button>
        <button type="button" id="captureBtn" disabled>æ’®å½±</button>
      </div>

      <div class="video-wrapper" id="videoWrapper">
        <video id="video" class="main" autoplay playsinline></video>
        <!-- overlay preview that toggles with camera display -->
        <img id="overlayPreview" class="overlay-preview" alt="æ’®å½±ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼" />
      </div>

      <!-- Zoom control (fallback + precise control) -->
      <div id="zoomControl" class="zoom-control">
        <input id="zoomSlider" type="range" min="1" max="1" step="0.1" value="1" />
        <div id="zoomValue" class="zoom-value">1.0x</div>
      </div>

      <!-- Brightness control (added under zoom) -->
      <div id="brightnessControl" class="brightness-control" title="æ˜ã‚‹ã•ã‚’èª¿æ•´ã—ã¾ã™ã€‚ä¸­å¤®ãŒ0ï¼ˆå¤‰åŒ–ãªã—ï¼‰">
        <!-- Range is -1 .. 1, 0 is neutral -->
        <input id="brightnessSlider" type="range" min="-1" max="1" step="0.01" value="0" />
        <div id="brightnessValue" class="brightness-value">0.00</div>
      </div>

      <!-- thumbnail preview shown after capture; clicking toggles overlay <-> camera -->
      <div class="preview-thumb" id="previewThumb" style="display:none;">
        <img id="preview" alt="ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒ" />
        <!-- mini simple camera container that will show a tiny live feed (no zoom/pan) -->
        <div class="mini-camera" id="miniCamContainer" title="ãƒŸãƒ‹ã‚«ãƒ¡ãƒ©ï¼ˆã‚¿ãƒƒãƒ—ã§ã‚µãƒ ãƒã‚¤ãƒ«/ã‚«ãƒ¡ãƒ©åˆ‡æ›¿ï¼‰">
          <video id="miniCam" autoplay playsinline muted></video>
        </div>

        <div class="txt">æ’®å½±æ¸ˆã¿ï¼ˆã‚¿ãƒƒãƒ—ã§ç¢ºèª/ã‚«ãƒ¡ãƒ©åˆ‡æ›¿ï¼‰</div>

        <!-- ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ï¼ˆæ’®ã£ãŸç”»åƒãŒã‚ã‚‹ã¨ãã«æœ‰åŠ¹åŒ–ï¼‰ -->
        <button type="button" id="downloadBtn" disabled title="æ’®ã£ãŸç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰">ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</button>
      </div>

      <button type="submit">AIã§åˆ¤å®š</button>
    </form>

    <div id="result" class="result"></div>
    <div class="muted">â€» ã‚«ãƒ¡ãƒ©ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ãƒ–ãƒ©ã‚¦ã‚¶ãŒã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ãƒ¢ãƒã‚¤ãƒ«ã§ã¯HTTPSãŒå¿…è¦ã§ã™ã€‚</div>
  </div>

  <script>
    // --- ãƒ¢ãƒ‡ãƒ«é–¢é€£ï¼ˆçœç•¥èª¬æ˜ã¯å‰å›ã¨åŒæ§˜ï¼‰ ---
    let model = null;
    let classes = ["å¥åº·", "ç—…æ°—"];
    const modelStatus = document.getElementById('modelStatus');
     //ã“ã“ã«URLã‚’æŒ¿å…¥â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
    const modelJsonUrl = "https://teachablemachine.withgoogle.com/models/k3U5df8h9/model.json";
     //â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²
    async function loadModelFromUrl(modelUrl) {
      modelStatus.textContent = "ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...";
      try {
        model = await tf.loadLayersModel(modelUrl);
        modelStatus.textContent = "ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚";
        const metaUrl = modelUrl.replace(/model\.json$/, "metadata.json");
        fetch(metaUrl).then(res => res.ok ? res.json() : null).then(json => { if (json && json.labels) classes = json.labels; }).catch(()=>{});
      } catch (e) {
        model = null;
        modelStatus.textContent = "ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚URLã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚";
      }
    }
    loadModelFromUrl(modelJsonUrl);

    // --- DOM ---
    const imageInput = document.getElementById('imageInput');
    const preview = document.getElementById('preview');
    const previewThumb = document.getElementById('previewThumb');
    const overlayPreview = document.getElementById('overlayPreview');
    const video = document.getElementById('video');
    const videoWrapper = document.getElementById('videoWrapper');
    const toggleCameraBtn = document.getElementById('toggleCamera');
    const switchCameraBtn = document.getElementById('switchCamera');
    const captureBtn = document.getElementById('captureBtn');
    const zoomControl = document.getElementById('zoomControl');
    const zoomSlider = document.getElementById('zoomSlider');
    const zoomValue = document.getElementById('zoomValue');

    const brightnessControl = document.getElementById('brightnessControl');
    const brightnessSlider = document.getElementById('brightnessSlider');
    const brightnessValue = document.getElementById('brightnessValue');

    const miniCamContainer = document.getElementById('miniCamContainer');
    const miniCam = document.getElementById('miniCam');

    const downloadBtn = document.getElementById('downloadBtn');

    // --- çŠ¶æ…‹ ---
    let inputImage = null;
    let stream = null;
    let isCameraOn = false;
    let currentFacingMode = "environment";
    let hardwareZoomSupported = false;
    let hardwareZoomRange = {min:1, max:1, step:0.1};
    let zoomFactor = 1;
    let brightnessFactor = 0; // -1 .. 1, 0 = neutral
    let panX = 0, panY = 0;
    let wrapperRect = null;

    // store the latest captured image (JPEG dataURL with EXIF if available)
    let lastCapturedDataUrl = null;
    // store capture metadata (timestamp, coords) for filename or any other use
    let lastCaptureMeta = null;

    // Two allowed states:
    // MAIN_VIEW: big camera (video shown) + small static thumbnail (preview shown, miniCam hidden)
    // OVERLAY_VIEW: big static image (overlayPreview visible) + small live miniCam (miniCamContainer shown, preview hidden)
    let viewState = 'MAIN_VIEW'; // 'MAIN_VIEW' or 'OVERLAY_VIEW'

    // --- Helper functions to enforce strict two-state toggle ---
    function setMainView() {
      viewState = 'MAIN_VIEW';
      overlayPreview.style.display = 'none';
      if (isCameraOn) video.style.display = 'block';
      hideMiniCam(false);
      if (preview.src) {
        previewThumb.style.display = 'flex';
        preview.style.display = 'block';
      }
    }

    function setOverlayView() {
      if (!overlayPreview.src) return;
      viewState = 'OVERLAY_VIEW';
      overlayPreview.style.display = 'block';
      video.style.display = 'none';
      showMiniCam();
    }

    // --- File input: show thumbnail but keep state consistent ---
    imageInput.addEventListener('change', function() {
      if (this.files && this.files[0]) {
        const fr = new FileReader();
        fr.onload = function(e) {
          preview.src = e.target.result;
          overlayPreview.src = e.target.result;
          // uploaded images should be shown as-is (not affected by live brightness slider)
          preview.removeAttribute('data-captured');
          overlayPreview.removeAttribute('data-captured');
          preview.style.filter = 'none';
          overlayPreview.style.filter = 'none';
          previewThumb.style.display = 'flex';
          setMainView();
          inputImage = new Image();
          inputImage.crossOrigin = "anonymous";
          inputImage.src = e.target.result;
          // disable download button for uploaded image (only enable for captured)
          downloadBtn.disabled = true;
          lastCapturedDataUrl = null;
          lastCaptureMeta = null;
        };
        fr.readAsDataURL(this.files[0]);
      } else {
        previewThumb.style.display = 'none';
        overlayPreview.style.display = 'none';
        inputImage = null;
      }
    });

    // --- Camera controls (start/stop/switch/capture) ---
    toggleCameraBtn.addEventListener('click', async () => {
      if (isCameraOn) {
        stopCamera();
      } else {
        try { await startCamera(); } catch (err) { console.error(err); alert('ã‚«ãƒ¡ãƒ©èµ·å‹•ã‚¨ãƒ©ãƒ¼'); }
      }
    });

    async function startCamera() {
      stopCamera();
      const tryConstraints = [
        { video: { facingMode: { exact: currentFacingMode } }, audio: false },
        { video: { facingMode: currentFacingMode }, audio: false },
        { video: true, audio: false }
      ];
      let got = false;
      for (const c of tryConstraints) {
        try {
          stream = await navigator.mediaDevices.getUserMedia(c);
          got = true;
          break;
        } catch (e) {}
      }
      if (!got || !stream) throw new Error('ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒ å–å¾—å¤±æ•—');

      video.srcObject = stream;
      video.style.display = 'block';
      previewThumb.style.display = preview.src ? 'flex' : 'none';
      captureBtn.disabled = false;
      switchCameraBtn.disabled = false;
      toggleCameraBtn.textContent = "ã‚«ãƒ¡ãƒ©åœæ­¢";
      isCameraOn = true;
      videoWrapper.style.touchAction = 'none';

      // reset zoom/pan
      zoomFactor = 1; panX = 0; panY = 0; applyVideoTransform();
      overlayPreview.style.display = 'none';

      // capabilities check for zoom
      const track = stream.getVideoTracks()[0];
      hardwareZoomSupported = false;
      try {
        const caps = track.getCapabilities ? track.getCapabilities() : {};
        const settings = track.getSettings ? track.getSettings() : {};
        if (caps && typeof caps.zoom !== 'undefined') {
          hardwareZoomSupported = true;
          hardwareZoomRange.min = caps.zoom.min || 1;
          hardwareZoomRange.max = caps.zoom.max || 1;
          hardwareZoomRange.step = caps.zoom.step || 0.1;
          const initialZoom = settings.zoom || hardwareZoomRange.min || 1;
          zoomFactor = clamp(initialZoom, hardwareZoomRange.min, hardwareZoomRange.max);
          setupZoomSlider(hardwareZoomRange.min, hardwareZoomRange.max, hardwareZoomRange.step, zoomFactor);
          video.style.transform = `translate(-50%,-50%) scale(1)`;
        } else {
          hardwareZoomSupported = false;
          setupZoomSlider(1, 3, 0.1, 1);
          video.style.transform = `translate(-50%,-50%) scale(1)`;
        }
      } catch (err) {
        hardwareZoomSupported = false;
        setupZoomSlider(1, 3, 0.1, 1);
        video.style.transform = `translate(-50%,-50%) scale(1)`;
      }

      // show brightness control (initial 0 = neutral)
      setupBrightnessSlider(-1, 1, 0.01, 0);

      // ensure state is MAIN_VIEW when camera starts
      setMainView();
    }

    function stopCamera() {
      if (stream) stream.getTracks().forEach(t => t.stop());
      stream = null;
      video.srcObject = null;
      video.style.display = 'none';
      captureBtn.disabled = true;
      switchCameraBtn.disabled = true;
      toggleCameraBtn.textContent = "ã‚«ãƒ¡ãƒ©èµ·å‹•";
      isCameraOn = false;
      hideZoomControl();
      hideBrightnessControl();
      zoomFactor = 1; brightnessFactor = 0; panX = 0; panY = 0; applyVideoTransform();
      video.style.filter = '';
      miniCam.style.filter = '';
      videoWrapper.style.touchAction = '';
      setMainView();
    }

    switchCameraBtn.addEventListener('click', async () => {
      switchCameraBtn.disabled = true;
      currentFacingMode = (currentFacingMode === 'environment') ? 'user' : 'environment';
      try { await startCamera(); } catch (err) {
        currentFacingMode = (currentFacingMode === 'environment') ? 'user' : 'environment';
        try { await startCamera(); } catch (_) {}
        alert('ã‚«ãƒ¡ãƒ©åˆ‡æ›¿ã«å¤±æ•—ã—ã¾ã—ãŸ');
      } finally { switchCameraBtn.disabled = false; }
    });

    // --- Helper: GPS and EXIF utilities ---
    function toExifDateString(d) {
      // "YYYY:MM:DD HH:MM:SS"
      const pad = (n) => String(n).padStart(2, '0');
      return `${d.getFullYear()}:${pad(d.getMonth()+1)}:${pad(d.getDate())} ${pad(d.getHours())}:${pad(d.getMinutes())}:${pad(d.getSeconds())}`;
    }
    function decimalToDMSRational(dec) {
      // return array of three rationals [[deg,1],[min,1],[secNum,secDen]]
      dec = Math.abs(dec);
      const deg = Math.floor(dec);
      const minf = (dec - deg) * 60;
      const minutes = Math.floor(minf);
      const sec = (minf - minutes) * 60;
      // use seconds with denominator 100 to keep integer
      const secNum = Math.round(sec * 100);
      const secDen = 100;
      return [[deg,1],[minutes,1],[secNum,secDen]];
    }

    // --- Capture: bake brightness into image and embed EXIF (date + optional GPS) ---
    captureBtn.addEventListener('click', async () => {
      if (!stream) return;
      const W = video.videoWidth; const H = video.videoHeight;
      if (!W || !H) return;

      // record capture metadata
      const captureTime = new Date();
      lastCaptureMeta = { capturedAt: captureTime, coords: null };

      // attempt to get geolocation but don't block too long (timeout 3000ms)
      const getPosition = () => new Promise((resolve) => {
        if (!navigator.geolocation) return resolve(null);
        let resolved = false;
        const success = (pos) => { if (!resolved) { resolved = true; resolve(pos.coords); } };
        const fail = () => { if (!resolved) { resolved = true; resolve(null); } };
        navigator.geolocation.getCurrentPosition(success, fail, { enableHighAccuracy: true, timeout: 3000, maximumAge: 60000 });
        // fallback timeout safety (in case getCurrentPosition never responds)
        setTimeout(() => { if (!resolved) { resolved = true; resolve(null); } }, 3500);
      });

      const positionPromise = getPosition();

      wrapperRect = videoWrapper.getBoundingClientRect();
      const wrapperW = Math.round(wrapperRect.width);
      const wrapperH = Math.round(wrapperRect.height);
      const scaleToFill = Math.max(wrapperW / W, wrapperH / H);
      const factor = zoomFactor || 1;
      const cropWsrc = Math.round(wrapperW / (scaleToFill * factor));
      const cropHsrc = Math.round(wrapperH / (scaleToFill * factor));
      const centerSourceX = W / 2 - (panX / (scaleToFill * factor));
      const centerSourceY = H / 2 - (panY / (scaleToFill * factor));
      let sx = Math.round(centerSourceX - cropWsrc / 2);
      let sy = Math.round(centerSourceY - cropHsrc / 2);
      if (sx < 0) sx = 0;
      if (sy < 0) sy = 0;
      if (sx + cropWsrc > W) sx = Math.max(0, W - cropWsrc);
      if (sy + cropHsrc > H) sy = Math.max(0, H - cropHsrc);
      const canvas = document.createElement('canvas');
      const size = Math.min(cropWsrc, cropHsrc);
      canvas.width = size; canvas.height = size;
      const ctx = canvas.getContext('2d');

      // Bake brightness into the image (so captured image visually matches what the user saw)
      const cssBrightnessMultiplier = 1 + brightnessFactor;
      try {
        ctx.filter = `brightness(${cssBrightnessMultiplier})`;
        ctx.drawImage(video, sx, sy, size, size, 0, 0, size, size);
      }
      catch (err) {
        console.warn('drawImage failed', err);
        ctx.filter = 'none';
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      }

      // produce JPEG (EXIF is for JPEG)
      const jpegDataUrl = canvas.toDataURL('image/jpeg', 0.92);

      // wait for position (but not longer than the internal timeout)
      const coords = await positionPromise;
      if (coords) lastCaptureMeta.coords = { latitude: coords.latitude, longitude: coords.longitude, altitude: coords.altitude };

      // Build EXIF with piexif (DateTimeOriginal + GPS if available)
      try {
        const exifObj = { "0th": {}, "Exif": {}, "GPS": {}, "1st": {}, "thumbnail": null };
        const dateStr = toExifDateString(captureTime);
        // Image DateTime (0th) and Exif DateTimeOriginal
        exifObj["0th"][piexif.ImageIFD.DateTime] = dateStr;
        exifObj["Exif"][piexif.ExifIFD.DateTimeOriginal] = dateStr;
        // If GPS available, set GPS tags
        if (coords) {
          const latRef = coords.latitude >= 0 ? "N" : "S";
          const lonRef = coords.longitude >= 0 ? "E" : "W";
          exifObj["GPS"][piexif.GPSIFD.GPSLatitudeRef] = latRef;
          exifObj["GPS"][piexif.GPSIFD.GPSLongitudeRef] = lonRef;
          exifObj["GPS"][piexif.GPSIFD.GPSLatitude] = decimalToDMSRational(coords.latitude);
          exifObj["GPS"][piexif.GPSIFD.GPSLongitude] = decimalToDMSRational(coords.longitude);
          if (typeof coords.altitude === 'number' && !isNaN(coords.altitude)) {
            // altitude rational: altitude * 100 / 100
            const altNum = Math.round(Math.abs(coords.altitude) * 100);
            exifObj["GPS"][piexif.GPSIFD.GPSAltitude] = [altNum, 100];
            exifObj["GPS"][piexif.GPSIFD.GPSAltitudeRef] = coords.altitude >= 0 ? 0 : 1;
          }
        }
        const exifbytes = piexif.dump(exifObj);
        const newDataUrl = piexif.insert(exifbytes, jpegDataUrl);
        lastCapturedDataUrl = newDataUrl;
      } catch (exifErr) {
        console.warn('EXIFåŸ‹ã‚è¾¼ã¿å¤±æ•—', exifErr);
        // fallback to raw jpeg
        lastCapturedDataUrl = jpegDataUrl;
      }

      // Set both static preview and overlay source with the baked image (JPEG with EXIF if available)
      preview.src = lastCapturedDataUrl;
      overlayPreview.src = lastCapturedDataUrl;

      // Mark these as captured so we do NOT modify their visual brightness later.
      preview.setAttribute('data-captured', 'true');
      overlayPreview.setAttribute('data-captured', 'true');

      // Ensure no CSS filter is applied to the preview/overlay so they display the baked pixels unchanged.
      preview.style.filter = 'none';
      overlayPreview.style.filter = 'none';

      previewThumb.style.display = 'flex';
      inputImage = new Image(); inputImage.crossOrigin = "anonymous"; inputImage.src = lastCapturedDataUrl;

      // enable download button
      downloadBtn.disabled = false;

      // IMPORTANT: after capture we MUST stay in MAIN_VIEW (big camera + small static thumbnail)
      setMainView();
    });

    // --- Thumbnail click handlers ---
    preview.addEventListener('click', (ev) => {
      if (!overlayPreview.src) return;
      if (viewState === 'MAIN_VIEW') setOverlayView(); else setMainView();
      ev.stopPropagation();
    });
    overlayPreview.addEventListener('click', (ev) => { setMainView(); ev.stopPropagation(); });

    // --- Mini camera logic (simple live feed in thumbnail area) ---
    function showMiniCam() {
      if (!stream) return;
      try {
        miniCam.srcObject = stream;
        miniCam.muted = true;
        miniCam.style.filter = `brightness(${1 + brightnessFactor})`;
        miniCam.play().catch(()=>{});
        miniCamContainer.style.display = 'block';
        preview.style.display = 'none';
      } catch (err) { console.warn('miniCam start failed', err); }
    }
    function hideMiniCam(detach = true) {
      miniCamContainer.style.display = 'none';
      if (detach) { try { miniCam.srcObject = null; } catch (_) {} }
      if (preview.src) preview.style.display = 'block';
    }
    miniCamContainer.addEventListener('click', (ev) => { if (!preview.src) return; setMainView(); ev.stopPropagation(); });
    miniCam.addEventListener('click', (ev) => { miniCamContainer.click(); ev.stopPropagation(); });

    // --- Download button handler ---
    downloadBtn.addEventListener('click', (ev) => {
      if (!lastCapturedDataUrl) return;
      // filename includes capture datetime if available
      let filename = 'sakura.jpg';
      if (lastCaptureMeta && lastCaptureMeta.capturedAt) {
        const d = lastCaptureMeta.capturedAt;
        const pad = (n)=>String(n).padStart(2,'0');
        filename = `sakura_${d.getFullYear()}${pad(d.getMonth()+1)}${pad(d.getDate())}_${pad(d.getHours())}${pad(d.getMinutes())}${pad(d.getSeconds())}.jpg`;
      }
      // create temporary link and click
      const a = document.createElement('a');
      a.href = lastCapturedDataUrl;
      a.download = filename;
      document.body.appendChild(a);
      a.click();
      a.remove();
    });

    // --- Zoom UI / gestures / pan (kept from previous implementation, unchanged) ---
    function setupZoomSlider(min, max, step, initial) {
      zoomSlider.min = min;
      zoomSlider.max = max;
      zoomSlider.step = step;
      zoomSlider.value = initial;
      zoomValue.textContent = parseFloat(initial).toFixed(1) + "x";
      zoomControl.style.display = 'flex';
      zoomSlider.oninput = async (e) => {
        const v = parseFloat(e.target.value);
        const s = { x: 0, y: 0 };
        await setZoom(v, s);
        zoomValue.textContent = v.toFixed(1) + "x";
      };
    }
    function hideZoomControl() { zoomControl.style.display = 'none'; zoomSlider.oninput = null; zoomFactor = 1; zoomValue.textContent = "1.0x"; }

    // --- Brightness control setup and handlers ---
    function setupBrightnessSlider(min, max, step, initial) {
      brightnessSlider.min = min;
      brightnessSlider.max = max;
      brightnessSlider.step = step;
      brightnessSlider.value = initial;
      brightnessValue.textContent = parseFloat(initial).toFixed(2);
      brightnessControl.style.display = 'flex';

      brightnessSlider.oninput = (e) => {
        const v = parseFloat(e.target.value);
        brightnessFactor = v;
        brightnessValue.textContent = (v >= 0 ? "+" : "") + v.toFixed(2);
        applyBrightness();
      };
      brightnessFactor = parseFloat(initial);
      applyBrightness();
    }

    function hideBrightnessControl() {
      brightnessControl.style.display = 'none';
      brightnessSlider.oninput = null;
      brightnessFactor = 0;
      brightnessValue.textContent = "0.00";
    }

    function applyBrightness() {
      const cssVal = 1 + (brightnessFactor || 0);
      // apply only to live video and miniCam; do NOT change saved preview/overlay images
      video.style.filter = `brightness(${cssVal})`;
      miniCam.style.filter = `brightness(${cssVal})`;
    }

    function applyVideoTransform() { video.style.transform = `translate(calc(-50% + ${panX}px), calc(-50% + ${panY}px)) scale(${zoomFactor})`; }

    async function setZoom(newZoom, s) {
      const oldZoom = zoomFactor || 1;
      const newPanX = (panX - s.x) * (newZoom / oldZoom) + s.x;
      const newPanY = (panY - s.y) * (newZoom / oldZoom) + s.y;
      zoomFactor = newZoom; panX = newPanX; panY = newPanY; clampPan(); applyVideoTransform();
      if (stream && typeof stream.getVideoTracks === 'function') {
        const track = stream.getVideoTracks()[0];
        try { await track.applyConstraints({ advanced: [{ zoom: clamp(zoomFactor, hardwareZoomRange.min, hardwareZoomRange.max) }] }); }
        catch (err) {}
      }
      if (zoomControl.style.display !== 'none') { zoomSlider.value = zoomFactor; zoomValue.textContent = zoomFactor.toFixed(1) + 'x'; }
    }
    function clampPan() {
      const W = video.videoWidth, H = video.videoHeight;
      if (!W || !H) return;
      wrapperRect = videoWrapper.getBoundingClientRect();
      const wrapperW = wrapperRect.width, wrapperH = wrapperRect.height;
      const scaleToFill = Math.max(wrapperW / W, wrapperH / H);
      const displayedWidth = W * scaleToFill, displayedHeight = H * scaleToFill;
      const visualWidth = displayedWidth * zoomFactor, visualHeight = displayedHeight * zoomFactor;
      const maxPanX = Math.max(0, (visualWidth - wrapperW) / 2), maxPanY = Math.max(0, (visualHeight - wrapperH) / 2);
      panX = clamp(panX, -maxPanX, maxPanX); panY = clamp(panY, -maxPanY, maxPanY);
    }
    function clamp(v, a, b) { return Math.max(a, Math.min(b, v)); }

    // gestures (pinch/pan)
    let isPanning = false, isPinching = false, pinchStartDist = 0, pinchStartZoom = 1;
    let pinchCenter = {x:0,y:0}, startPanX = 0, startPanY = 0, panStart = {x:0,y:0};
    function getTouchDist(t1,t2){const dx=t2.clientX-t1.clientX,dy=t2.clientY-t1.clientY;return Math.hypot(dx,dy);}
    function getTouchMid(t1,t2){return {x:(t1.clientX+t2.clientX)/2,y:(t1.clientY+t2.clientY)/2};}

    videoWrapper.addEventListener('touchstart', (ev) => {
      if (!isCameraOn) return;
      if (viewState !== 'MAIN_VIEW') return;
      ev.preventDefault();
      wrapperRect = videoWrapper.getBoundingClientRect();
      if (ev.touches.length === 1) {
        isPanning = true; isPinching = false;
        startPanX = panX; startPanY = panY;
        panStart = { x: ev.touches[0].clientX, y: ev.touches[0].clientY };
      } else if (ev.touches.length === 2) {
        isPinching = true; isPanning = false;
        pinchStartDist = getTouchDist(ev.touches[0], ev.touches[1]);
        pinchStartZoom = zoomFactor || 1;
        const mid = getTouchMid(ev.touches[0], ev.touches[1]);
        pinchCenter = { x: mid.x - wrapperRect.left - wrapperRect.width / 2, y: mid.y - wrapperRect.top - wrapperRect.height / 2 };
        panStart = { x: panX, y: panY };
      }
    }, { passive: false });

    videoWrapper.addEventListener('touchmove', (ev) => {
      if (!isCameraOn) return;
      if (viewState !== 'MAIN_VIEW') return;
      ev.preventDefault();
      wrapperRect = videoWrapper.getBoundingClientRect();
      if (isPinching && ev.touches.length >= 2) {
        const dist = getTouchDist(ev.touches[0], ev.touches[1]);
        if (pinchStartDist <= 0) return;
        let scale = dist / pinchStartDist;
        let newZoom = pinchStartZoom * scale;
        const minZoom = parseFloat(zoomSlider.min || 1), maxZoom = parseFloat(zoomSlider.max || 3);
        newZoom = clamp(newZoom, minZoom, maxZoom);
        const s = { x: pinchCenter.x, y: pinchCenter.y };
        panX = (panStart.x - s.x) * (newZoom / pinchStartZoom) + s.x;
        panY = (panStart.y - s.y) * (newZoom / pinchStartZoom) + s.y;
        zoomFactor = newZoom; clampPan(); applyVideoTransform();
        if (zoomControl.style.display !== 'none') { zoomSlider.value = zoomFactor; zoomValue.textContent = zoomFactor.toFixed(1) + 'x'; }
      } else if (isPanning && ev.touches.length === 1) {
        const dx = ev.touches[0].clientX - panStart.x;
        const dy = ev.touches[0].clientY - panStart.y;
        panX = startPanX + dx; panY = startPanY + dy; clampPan(); applyVideoTransform();
      }
    }, { passive: false });

    videoWrapper.addEventListener('touchend', (ev) => {
      if (!isCameraOn) return;
      if (viewState !== 'MAIN_VIEW') return;
      ev.preventDefault();
      if (ev.touches.length === 0) { isPanning = false; isPinching = false; }
      else if (ev.touches.length === 1) {
        isPinching = false; isPanning = true;
        startPanX = panX; startPanY = panY; panStart = { x: ev.touches[0].clientX, y: ev.touches[0].clientY };
      }
    }, { passive: false });

    // mouse drag & wheel only active in MAIN_VIEW
    let isMouseDown = false, mouseStart = {x:0,y:0};
    videoWrapper.addEventListener('mousedown', (ev) => {
      if (!isCameraOn) return; if (viewState !== 'MAIN_VIEW') return;
      ev.preventDefault(); isMouseDown = true; mouseStart = { x: ev.clientX, y: ev.clientY }; startPanX = panX; startPanY = panY;
    });
    window.addEventListener('mousemove', (ev) => {
      if (!isCameraOn) return; if (viewState !== 'MAIN_VIEW') return;
      if (!isMouseDown) return;
      const dx = ev.clientX - mouseStart.x, dy = ev.clientY - mouseStart.y;
      panX = startPanX + dx; panY = startPanY + dy; clampPan(); applyVideoTransform();
    });
    window.addEventListener('mouseup', () => { if (!isCameraOn) return; isMouseDown = false; });

    videoWrapper.addEventListener('wheel', (ev) => {
      if (!isCameraOn) return; if (viewState !== 'MAIN_VIEW') return;
      ev.preventDefault();
      const delta = -ev.deltaY; const zoomChange = delta > 0 ? 1.05 : 0.95;
      const newZoom = clamp(zoomFactor * zoomChange, parseFloat(zoomSlider.min || 1), parseFloat(zoomSlider.max || 3));
      wrapperRect = videoWrapper.getBoundingClientRect();
      const s = { x: ev.clientX - wrapperRect.left - wrapperRect.width/2, y: ev.clientY - wrapperRect.top - wrapperRect.height/2 };
      setZoom(newZoom, s);
    }, { passive: false });

    // --- Model preprocessing & predict (unchanged) ---
    function preprocessImage(img, size=224) {
      const canvas = document.createElement('canvas'); canvas.width = size; canvas.height = size;
      const ctx = canvas.getContext('2d'); ctx.drawImage(img, 0, 0, size, size);
      let tensor = tf.browser.fromPixels(canvas).expandDims(0).toFloat().div(tf.scalar(255));
      return tensor;
    }
    document.getElementById('sakuraForm').addEventListener('submit', async function(e) {
      e.preventDefault();
      const resultDiv = document.getElementById('result');
      if (!inputImage || !model) { resultDiv.innerHTML = "ç”»åƒã¨ãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"; return; }
      resultDiv.textContent = "åˆ¤å®šä¸­...";
      inputImage.onload = async () => {
        try {
          let inputSize = 224;
          try {
            if (model.inputs && model.inputs[0] && model.inputs[0].shape) {
              const s = model.inputs[0].shape;
              if (s.length >= 3 && s[1] && s[2]) {
                if (s[1] === s[2]) inputSize = s[1]; else inputSize = Math.max(s[1], s[2]);
              }
            }
          } catch (_) {}
          const tensor = preprocessImage(inputImage, inputSize);
          const predictionTensor = model.predict(tensor);
          let prediction;
          if (Array.isArray(predictionTensor)) prediction = await predictionTensor[0].data(); else prediction = await predictionTensor.data();
          let idx = 0; for (let i = 1; i < prediction.length; i++) if (prediction[i] > prediction[idx]) idx = i;
          const prob = (prediction[idx] * 100).toFixed(1); const label = classes[idx] || `ã‚¯ãƒ©ã‚¹${idx+1}`;
          if (label.includes("å¥åº·") || label.toLowerCase().includes("healthy")) resultDiv.innerHTML = `<span class="healthy">âœ… ${label}ã§ã™ï¼ (${prob}%)</span>`;
          else if (label.includes("ç—…æ°—") || label.toLowerCase().includes("sick")) resultDiv.innerHTML = `<span class="sick">âš ï¸ ${label}ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ (${prob}%)</span>`;
          else resultDiv.innerHTML = `<span>${label} (${prob}%)</span>`;
        } catch (err) {
          console.error(err);
          resultDiv.innerHTML = "åˆ¤å®šã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç”»åƒã‚„ãƒ¢ãƒ‡ãƒ«ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚";
        }
      };
      if (inputImage.complete) inputImage.onload();
    });

    // resize handling
    window.addEventListener('resize', () => { clampPan(); applyVideoTransform(); });

    // cleanup
    window.addEventListener('beforeunload', () => { if (stream) stream.getTracks().forEach(t => t.stop()); });

  </script>
</body>
</html>
