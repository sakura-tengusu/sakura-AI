<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>ã‚µã‚¯ãƒ©å¥åº·åˆ¤æ–­AI</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.16.0/dist/tf.min.js"></script>
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <style>
    body { font-family: sans-serif; background: #f2f2f2; padding: 2em; }
    .container { background: #fff; max-width: 420px; margin: auto; border-radius: 10px; box-shadow: 0 0 10px #ccc; padding: 2em; }
    h1 { color: #c46b9e; text-align: center; }
    label { display: block; margin-top: 1em; }
    input[type="file"] { width: 100%; }
    .controls { display: flex; gap: 0.5em; margin-top: 0.8em; }
    .controls button { flex: 1; padding: 0.6em; background: #c46b9e; color: #fff; border: none; border-radius: 5px; font-size: 0.95em; cursor: pointer; }
    button[type="submit"] { margin-top: 1.2em; width: 100%; padding: 0.8em; background: #c46b9e; color: #fff; border: none; border-radius: 5px; font-size: 1.1em; cursor: pointer; }
    .result { margin-top: 2em; font-size: 1.2em; text-align: center; }
    .healthy { color: #2bbd7e; }
    .sick { color: #e84c3d; }
    .preview { margin-top: 1em; max-width: 100%; border-radius: 8px; display:block; }
    .model-status { font-size: 0.95em; color: #888; margin-top: 0.5em; text-align: center; }
    /* ãƒ“ãƒ‡ã‚ªãƒ©ãƒƒãƒ‘ãƒ¼ï¼šæ ã®ä½ç½®ã¨ã‚µã‚¤ã‚ºã¯ã“ã“ã§å›ºå®šã—ã€å†…éƒ¨ã®videoã‚’æ‹¡å¤§ç¸®å°ã—ã¦ã‚‚æ ã¯å¤‰ã‚ã‚‰ãªã„ */
    .video-wrapper {
      width: 100%;
      aspect-ratio: 1 / 1; /* æ­£æ–¹å½¢æ ã€‚å¿…è¦ãªã‚‰å¤‰æ›´ */
      position: relative;
      overflow: hidden;
      border-radius: 8px;
      background: #000;
      margin-top: 1em;
    }
    /* video ã¯ãƒ©ãƒƒãƒ‘ãƒ¼å†…ã§ä¸­å¤®ã«é…ç½®ã—ã€transformã§æ‹¡å¤§ã—ã¦ã‚‚è¦ªãŒæº¢ã‚Œã‚’éš ã™ */
    video {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%) scale(1);
      transform-origin: center center;
      /* å‹•ç”»ãŒæ ã‚’è¦†ã†ã‚ˆã†ã« fill */
      min-width: 100%;
      min-height: 100%;
      width: auto;
      height: auto;
      display: none;
    }
    .zoom-control { margin-top: 0.6em; display: none; align-items: center; gap: 0.6em; }
    .zoom-control input[type="range"] { width: 100%; }
    .zoom-value { min-width: 48px; text-align: right; font-size: 0.95em; color: #444; }
    .small-note { font-size: 0.85em; color: #666; margin-top:0.5em; text-align:center; }
    .muted { color:#888; font-size:0.9em; margin-top:0.5em; text-align:center; }
  </style>
</head>
<body>
  <div class="container">
    <h1>ğŸŒ¸ã‚µã‚¯ãƒ©å¥åº·åˆ¤æ–­AIğŸŒ¸</h1>
    <div id="modelStatus" class="model-status"></div>
    <form id="sakuraForm">
      <label>ã‚µã‚¯ãƒ©ã®å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ã‚«ãƒ¡ãƒ©ã§æ’®å½±ã—ã¦ãã ã•ã„</label>

      <input type="file" id="imageInput" accept="image/*">

      <div class="controls">
        <button type="button" id="toggleCamera">ã‚«ãƒ¡ãƒ©èµ·å‹•</button>
        <button type="button" id="switchCamera" disabled>ã‚«ãƒ¡ãƒ©åˆ‡æ›¿</button>
        <button type="button" id="captureBtn" disabled>æ’®å½±</button>
      </div>

      <!-- ãƒ©ãƒƒãƒ‘ãƒ¼ã‚’è¿½åŠ : ã“ã®æ ã¯å¸¸ã«åŒã˜ä½ç½®ãƒ»ã‚µã‚¤ã‚ºã‚’ä¿ã¡ã€å†…éƒ¨ãƒ“ãƒ‡ã‚ªã¯æ‹¡å¤§ã—ã¦ã‚‚æº¢ã‚Œã¯éš ã‚Œã‚‹ -->
      <div class="video-wrapper" id="videoWrapper">
        <video id="video" autoplay playsinline></video>
      </div>

      <!-- Zoom control -->
      <div id="zoomControl" class="zoom-control">
        <input id="zoomSlider" type="range" min="1" max="1" step="0.1" value="1" />
        <div id="zoomValue" class="zoom-value">1.0x</div>
      </div>

      <img id="preview" class="preview" style="display:none;" alt="ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒ" />

      <button type="submit">AIã§åˆ¤å®š</button>
    </form>

    <div id="result" class="result"></div>
    <div class="muted">â€» ã‚«ãƒ¡ãƒ©ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ãƒ–ãƒ©ã‚¦ã‚¶ãŒã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ãƒ¢ãƒã‚¤ãƒ«ã§ã¯HTTPSãŒå¿…è¦ã§ã™ã€‚</div>
  </div>

  <script>
    // ãƒ¢ãƒ‡ãƒ«é–¢é€£
    let model = null;
    let classes = ["å¥åº·", "ç—…æ°—"];
    const modelStatus = document.getElementById('modelStatus');
    const modelJsonUrl = "https://teachablemachine.withgoogle.com/models/k3U5df8h9/model.json";

    async function loadModelFromUrl(modelUrl) {
      modelStatus.textContent = "ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...";
      try {
        model = await tf.loadLayersModel(modelUrl);
        modelStatus.textContent = "ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚";
        const metaUrl = modelUrl.replace(/model\.json$/, "metadata.json");
        fetch(metaUrl).then(res => res.ok ? res.json() : null).then(json => { if (json && json.labels) classes = json.labels; }).catch(()=>{});
      } catch (e) {
        model = null;
        modelStatus.textContent = "ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚URLã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚";
      }
    }
    loadModelFromUrl(modelJsonUrl);

    // DOM
    const imageInput = document.getElementById('imageInput');
    const preview = document.getElementById('preview');
    const video = document.getElementById('video');
    const videoWrapper = document.getElementById('videoWrapper');
    const toggleCameraBtn = document.getElementById('toggleCamera');
    const switchCameraBtn = document.getElementById('switchCamera');
    const captureBtn = document.getElementById('captureBtn');
    const zoomControl = document.getElementById('zoomControl');
    const zoomSlider = document.getElementById('zoomSlider');
    const zoomValue = document.getElementById('zoomValue');

    // state
    let inputImage = null;
    let stream = null;
    let isCameraOn = false;
    let currentFacingMode = "environment"; // "environment" or "user"
    let hardwareZoomSupported = false;
    let hardwareZoomRange = {min:1, max:1, step:0.1};
    let zoomFactor = 1; // ç¾åœ¨ã®ã‚ºãƒ¼ãƒ å€¤ï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼æ“ä½œã§æ›´æ–°ï¼‰

    // ãƒ•ã‚¡ã‚¤ãƒ«å…¥åŠ›
    imageInput.addEventListener('change', function() {
      if (this.files && this.files[0]) {
        const fr = new FileReader();
        fr.onload = function(e) {
          preview.src = e.target.result;
          preview.style.display = 'block';
          video.style.display = 'none';
          inputImage = new Image();
          inputImage.crossOrigin = "anonymous";
          inputImage.src = e.target.result;
        };
        fr.readAsDataURL(this.files[0]);
      } else {
        preview.style.display = 'none';
        inputImage = null;
      }
    });

    // ã‚«ãƒ¡ãƒ©èµ·å‹•/åœæ­¢ãƒˆã‚°ãƒ«
    toggleCameraBtn.addEventListener('click', async () => {
      if (isCameraOn) {
        stopCamera();
      } else {
        try {
          await startCamera();
        } catch (err) {
          console.error(err);
          alert('ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚è¨±å¯ã®ç¢ºèªã‚„åˆ¥ã®ãƒ–ãƒ©ã‚¦ã‚¶ã§å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚');
        }
      }
    });

    async function startCamera() {
      stopCamera(); // æ—¢å­˜ãŒã‚ã‚Œã°åœæ­¢
      const tryConstraints = [
        { video: { facingMode: { exact: currentFacingMode } }, audio: false },
        { video: { facingMode: currentFacingMode }, audio: false },
        { video: true, audio: false }
      ];
      let got = false;
      for (const c of tryConstraints) {
        try {
          stream = await navigator.mediaDevices.getUserMedia(c);
          got = true;
          break;
        } catch (e) {
          // æ¬¡ã¸
        }
      }
      if (!got || !stream) throw new Error('ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒ å–å¾—å¤±æ•—');

      video.srcObject = stream;
      video.style.display = 'block';
      preview.style.display = 'none';
      captureBtn.disabled = false;
      switchCameraBtn.disabled = false;
      toggleCameraBtn.textContent = "ã‚«ãƒ¡ãƒ©åœæ­¢";
      isCameraOn = true;

      // ã‚ºãƒ¼ãƒ å¯¾å¿œãƒã‚§ãƒƒã‚¯
      const track = stream.getVideoTracks()[0];
      hardwareZoomSupported = false;
      zoomFactor = 1;
      try {
        const caps = track.getCapabilities ? track.getCapabilities() : {};
        const settings = track.getSettings ? track.getSettings() : {};
        if (caps && typeof caps.zoom !== 'undefined') {
          hardwareZoomSupported = true;
          hardwareZoomRange.min = caps.zoom.min || 1;
          hardwareZoomRange.max = caps.zoom.max || 1;
          hardwareZoomRange.step = caps.zoom.step || 0.1;
          const initialZoom = settings.zoom || hardwareZoomRange.min || 1;
          zoomFactor = clamp(initialZoom, hardwareZoomRange.min, hardwareZoomRange.max);
          setupZoomSlider(hardwareZoomRange.min, hardwareZoomRange.max, hardwareZoomRange.step, zoomFactor);
          // ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚ºãƒ¼ãƒ å¯¾å¿œãªã‚‰è¦‹ãŸç›®ã¯é€šå¸¸ã‚¹ã‚±ãƒ¼ãƒ«(1)ã«ã—ã¦ãŠãï¼ˆå®Ÿéš›ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¯trackãŒæ‹¡å¤§ã™ã‚‹ï¼‰
          video.style.transform = 'translate(-50%, -50%) scale(1)';
        } else {
          // ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚ºãƒ¼ãƒ éå¯¾å¿œã®å ´åˆã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚ºãƒ¼ãƒ ã®ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’å‡ºã™
          hardwareZoomSupported = false;
          setupZoomSlider(1, 3, 0.1, 1);
          // åˆæœŸã¯ scale(1)
          video.style.transform = 'translate(-50%, -50%) scale(1)';
        }
      } catch (err) {
        hardwareZoomSupported = false;
        setupZoomSlider(1, 3, 0.1, 1);
        video.style.transform = 'translate(-50%, -50%) scale(1)';
      }
    }

    function stopCamera() {
      if (stream) {
        stream.getTracks().forEach(t => t.stop());
      }
      stream = null;
      video.srcObject = null;
      video.style.display = 'none';
      captureBtn.disabled = true;
      switchCameraBtn.disabled = true;
      toggleCameraBtn.textContent = "ã‚«ãƒ¡ãƒ©èµ·å‹•";
      isCameraOn = false;
      hideZoomControl();
      // reset transform
      video.style.transform = 'translate(-50%, -50%) scale(1)';
    }

    // ã‚«ãƒ¡ãƒ©åˆ‡æ›¿
    switchCameraBtn.addEventListener('click', async () => {
      switchCameraBtn.disabled = true;
      currentFacingMode = (currentFacingMode === 'environment') ? 'user' : 'environment';
      try {
        await startCamera();
      } catch (err) {
        currentFacingMode = (currentFacingMode === 'environment') ? 'user' : 'environment';
        try { await startCamera(); } catch (_) {}
        alert('ã‚«ãƒ¡ãƒ©ã®åˆ‡æ›¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‡ãƒã‚¤ã‚¹ãŒå¯¾å¿œã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚');
        console.error(err);
      } finally {
        switchCameraBtn.disabled = false;
      }
    });

    // æ’®å½±ï¼ˆã‚ºãƒ¼ãƒ ã¯ zoomFactor ã«åŸºã¥ã„ã¦ä¸­å¤®ã‚¯ãƒ­ãƒƒãƒ—ã—ã¦åæ˜ ï¼‰
    captureBtn.addEventListener('click', () => {
      if (!stream) return;
      const width = video.videoWidth;
      const height = video.videoHeight;
      if (!width || !height) return;

      const factor = zoomFactor || 1;
      const cropW = Math.round(width / factor);
      const cropH = Math.round(height / factor);
      const sx = Math.max(0, Math.floor((width - cropW) / 2));
      const sy = Math.max(0, Math.floor((height - cropH) / 2));

      const canvas = document.createElement('canvas');
      const size = Math.min(cropW, cropH);
      canvas.width = size;
      canvas.height = size;
      const ctx = canvas.getContext('2d');
      ctx.drawImage(video, sx, sy, size, size, 0, 0, size, size);

      const dataUrl = canvas.toDataURL('image/png');
      preview.src = dataUrl;
      preview.style.display = 'block';
      inputImage = new Image();
      inputImage.crossOrigin = "anonymous";
      inputImage.src = dataUrl;
      video.style.display = 'none';
    });

    // Zoom UI è¨­å®š
    function setupZoomSlider(min, max, step, initial) {
      zoomSlider.min = min;
      zoomSlider.max = max;
      zoomSlider.step = step;
      zoomSlider.value = initial;
      zoomValue.textContent = parseFloat(initial).toFixed(1) + "x";
      zoomControl.style.display = 'flex';
      zoomSlider.oninput = async (e) => {
        const v = parseFloat(e.target.value);
        zoomFactor = v;
        zoomValue.textContent = v.toFixed(1) + "x";
        if (stream && hardwareZoomSupported) {
          const track = stream.getVideoTracks()[0];
          try {
            await track.applyConstraints({ advanced: [{ zoom: v }] });
            // hardware zoom ã§ã¯è¦‹ãŸç›®ã® scale ã¯ 1 ã®ã¾ã¾ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ è‡ªä½“ãŒã‚ºãƒ¼ãƒ ã•ã‚Œã‚‹ï¼‰
            video.style.transform = 'translate(-50%, -50%) scale(1)';
          } catch (err) {
            // å¤±æ•—ã—ãŸã‚‰ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚ºãƒ¼ãƒ ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            console.warn('applyConstraints zoom failed, fallback to software zoom', err);
            applySoftwareVideoZoom(v);
          }
        } else {
          applySoftwareVideoZoom(v);
        }
      };
    }

    function hideZoomControl() {
      zoomControl.style.display = 'none';
      zoomSlider.oninput = null;
      zoomFactor = 1;
      zoomValue.textContent = "1.0x";
    }

    // ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚ºãƒ¼ãƒ ï¼švideo ã‚’ãƒ©ãƒƒãƒ‘ãƒ¼å†…ã§æ‹¡å¤§ï¼ˆè¦‹ãŸç›®ã ã‘ï¼‰ã€‚ãƒ©ãƒƒãƒ‘ãƒ¼ãŒ overflow:hidden ã®ãŸã‚
    // è¦‹ãŸç›®ã®æ ä½ç½®ãƒ»ã‚µã‚¤ã‚ºã¯å¤‰ã‚ã‚Šã¾ã›ã‚“ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æœ›ã«å¯¾å¿œï¼‰
    function applySoftwareVideoZoom(v) {
      // ä¸­å¿ƒã«æ‹¡å¤§ã™ã‚‹ï¼ˆãƒ©ãƒƒãƒ‘ãƒ¼ãŒæº¢ã‚Œã‚’éš ã™ã®ã§å‘¨ã‚Šã®UIã¯éš ã‚Œãªã„ï¼‰
      video.style.transform = `translate(-50%, -50%) scale(${v})`;
    }

    function clamp(v, min, max) {
      return Math.max(min, Math.min(max, v));
    }

    // ç”»åƒå‰å‡¦ç†ï¼ˆãƒ¢ãƒ‡ãƒ«ç”¨ï¼‰
    function preprocessImage(img, size=224) {
      const canvas = document.createElement('canvas');
      canvas.width = size;
      canvas.height = size;
      const ctx = canvas.getContext('2d');
      ctx.drawImage(img, 0, 0, size, size);
      let tensor = tf.browser.fromPixels(canvas)
        .expandDims(0)
        .toFloat()
        .div(tf.scalar(255));
      return tensor;
    }

    // åˆ¤å®š
    document.getElementById('sakuraForm').addEventListener('submit', async function(e) {
      e.preventDefault();
      const resultDiv = document.getElementById('result');
      if (!inputImage || !model) {
        resultDiv.innerHTML = "ç”»åƒã¨ãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚";
        return;
      }
      resultDiv.textContent = "åˆ¤å®šä¸­...";
      inputImage.onload = async () => {
        try {
          let inputSize = 224;
          try {
            if (model.inputs && model.inputs[0] && model.inputs[0].shape) {
              const s = model.inputs[0].shape;
              if (s.length >= 3 && s[1] && s[2]) {
                if (s[1] === s[2]) inputSize = s[1];
                else inputSize = Math.max(s[1], s[2]);
              }
            }
          } catch (_) {}
          const tensor = preprocessImage(inputImage, inputSize);
          const predictionTensor = model.predict(tensor);
          let prediction;
          if (Array.isArray(predictionTensor)) {
            prediction = await predictionTensor[0].data();
          } else {
            prediction = await predictionTensor.data();
          }
          let idx = 0;
          for (let i = 1; i < prediction.length; i++) {
            if (prediction[i] > prediction[idx]) idx = i;
          }
          const prob = (prediction[idx] * 100).toFixed(1);
          const label = classes[idx] || `ã‚¯ãƒ©ã‚¹${idx+1}`;
          if (label.includes("å¥åº·") || label.toLowerCase().includes("healthy")) {
            resultDiv.innerHTML = `<span class="healthy">âœ… ${label}ã§ã™ï¼ (${prob}%)</span>`;
          } else if (label.includes("ç—…æ°—") || label.toLowerCase().includes("sick")) {
            resultDiv.innerHTML = `<span class="sick">âš ï¸ ${label}ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ (${prob}%)</span>`;
          } else {
            resultDiv.innerHTML = `<span>${label} (${prob}%)</span>`;
          }
        } catch (err) {
          console.error(err);
          resultDiv.innerHTML = "åˆ¤å®šã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç”»åƒã‚„ãƒ¢ãƒ‡ãƒ«ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚";
        }
      };
      if (inputImage.complete) inputImage.onload();
    });

    // ãƒšãƒ¼ã‚¸é›¢è„±ã§ã‚«ãƒ¡ãƒ©è§£æ”¾
    window.addEventListener('beforeunload', () => {
      if (stream) stream.getTracks().forEach(t => t.stop());
    });
  </script>
</body>
</html>
